{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9067426d",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Google Colab GPU\n",
    "\n",
    "This notebook implements hyperparameter tuning for our ML project using Google Colab's GPU capabilities. Follow these steps to run the tuning process:\n",
    "\n",
    "1. Mount Google Drive\n",
    "2. Install dependencies\n",
    "3. Import project files\n",
    "4. Run hyperparameter tuning with GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e5281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab4229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project directory to path\n",
    "project_path = '/content/drive/MyDrive/path/to/your/project'  # Update this path\n",
    "sys.path.append(project_path)\n",
    "\n",
    "# Import project modules\n",
    "import config\n",
    "import cv_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd8faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU-accelerated logistic regression implementation\n",
    "class LogisticRegressionGPU(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionGPU, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "def train_logistic_regression_gpu(X, y, lambda_, gamma, max_iters):\n",
    "    # Convert data to PyTorch tensors and move to GPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    y_tensor = torch.FloatTensor(y).to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = LogisticRegressionGPU(X.shape[1]).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=gamma)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(max_iters):\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            # Forward pass\n",
    "            outputs = model(batch_X).squeeze()\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # L2 regularization\n",
    "            l2_reg = torch.tensor(0.).to(device)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            loss += lambda_ * l2_reg\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Get weights and bias\n",
    "    weights = model.linear.weight.data.cpu().numpy().flatten()\n",
    "    bias = model.linear.bias.data.cpu().numpy()[0]\n",
    "    \n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caed4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU-accelerated grid search with cross-validation\n",
    "def grid_search_cv_gpu(X, y, lambda_grid=config.LAMBDA, gamma_grid=config.GAMMA, max_iters=config.MAX_ITERS):\n",
    "    \"\"\"\n",
    "    Perform grid search over hyperparameters using cross-validation with GPU acceleration.\n",
    "    \"\"\"\n",
    "    print(f\"[Grid Search] Testing {len(lambda_grid) * len(gamma_grid)} hyperparameter combinations...\")\n",
    "    print(f\"Using device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for lambda_ in lambda_grid:\n",
    "        for gamma in gamma_grid:\n",
    "            # Perform cross-validation for this parameter combination\n",
    "            cv_results = cv_utils.cross_validate_logistic_regression(\n",
    "                y, X, lambda_, gamma, max_iters,\n",
    "                train_func=train_logistic_regression_gpu  # Use GPU-accelerated training\n",
    "            )\n",
    "            results.append(cv_results)\n",
    "    \n",
    "    # Find best configuration by F1 score\n",
    "    best_result = max(results, key=lambda r: r['mean_f1'])\n",
    "    \n",
    "    print(f\"\\n[BEST CV] lambda={best_result['lambda']:.3e}, \"\n",
    "          f\"gamma={best_result['learning_rate']:.3e}, \"\n",
    "          f\"threshold={best_result['optimal_threshold']:.3f}\")\n",
    "    print(f\"          F1={best_result['mean_f1']:.4f} (±{best_result['std_f1']:.4f}), \"\n",
    "          f\"Acc={best_result['mean_accuracy']:.4f} (±{best_result['std_accuracy']:.4f})\")\n",
    "    \n",
    "    return best_result, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def load_data():\n",
    "    \"\"\"Load training data from the data directory.\"\"\"\n",
    "    data_dir = os.path.join(project_path, 'data/dataset')\n",
    "    \n",
    "    # Load training data\n",
    "    x_train = np.loadtxt(os.path.join(data_dir, 'x_train.csv'), delimiter=',', skiprows=1)\n",
    "    y_train = np.loadtxt(os.path.join(data_dir, 'y_train.csv'), delimiter=',', skiprows=1)\n",
    "    \n",
    "    print(f\"Loaded training data: X shape={x_train.shape}, y shape={y_train.shape}\")\n",
    "    return x_train, y_train\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "def tune_gpu(X, y):\n",
    "    \"\"\"Main tuning function with GPU acceleration.\"\"\"\n",
    "    if config.HYPERPARAM_TUNING:\n",
    "        best_result, results_list = grid_search_cv_gpu(X, y)\n",
    "        save_tuning_results(best_result, results_list)\n",
    "    else:\n",
    "        best_result = load_tuning_results()\n",
    "    \n",
    "    return best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a5d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the hyperparameter tuning\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    X, y = load_data()\n",
    "    \n",
    "    # Run tuning\n",
    "    best_params = tune_gpu(X, y)\n",
    "    \n",
    "    print(\"\\nBest parameters found:\")\n",
    "    print(f\"Lambda: {best_params['lambda']:.6e}\")\n",
    "    print(f\"Learning rate (gamma): {best_params['learning_rate']:.6e}\")\n",
    "    print(f\"Optimal threshold: {best_params['optimal_threshold']:.6f}\")\n",
    "    print(f\"F1 score: {best_params['mean_f1']:.4f} (±{best_params['std_f1']:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
